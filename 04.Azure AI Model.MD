### Azure AI Model Setup
  * The ``` ai init ``` inference command initializes the connection to the Azure AI Inference endpoint.
  * This initialization is required to use the models available in the Azure AI Model Catalog with the Azure AI CLI or with the Azure AI Inference SDK packages.

  * Initialize connection to Azure AI Inference Endpoint
    ```
      ai init inference
  
      STEP 1: ⇛ Enter your Azure AI Inference endpoint
      STEP 2: ⇛ Enter your Azure AI Inference key
    ```
  
    * If you don't have an Azure AI Inference endpoint...
      * <a href="https://ai.azure.com/explore/models">Azure AI Foundry Model Catalog</a> - Explore the Azure AI Model Catalog and Deploy a model to an endpoint
      * <img src="https://github.com/mkader/Book-of-AI---Azure/blob/main/img/03.01.azure ai foundry.png" height=200>
  
      * <a href="https://learn.microsoft.com/en-us/azure/ai-studio/how-to/deploy-models-serverless?tabs=azure-ai-studio">Azure AI Serverless Model Documentation</a> - Learn how to deploy an Azure AI Serverless Model to a new Azure AI Inference endpoint.

  * View Configuration
  ```
    # Get chat endpoint
    ai config @chat.endpoint

    #Get chat key
    ai config @chat.key
  ```

### Azure AI Model Chat Basics

 * The ai chat command allows you to interact w/ Azure AI models from the command line.

 * User and System Prompts - The ``` ai chat ``` command sends a user prompt to GitHub's AI Inference service and displays the response.
    * User prompts are questions or statements to the model
     ```
      ai chat --user "What is the capital of France?"
     ```
    * System prompts are special instructions for the model
     ```
      ai chat --user "What is the capital of France." --system "Always answer in French."
     ```
    * --question is an alias for --user
     ```
      ai chat --question "What is the capital of France?"
     ```

 * User and System prompts from Files
    * User prompt from a file
     ```
      ai chat --question "@question.txt"
     ```
    * System prompt from a file
     ```
      ai chat --question "What is the capital of France?" --system "@system.txt"
     ```
 * Interactive Chat - The --interactive flag allows back-and-forth conversations with the model.
   * Interactive chat
    ```
     ai chat --interactive
    ```
   * Interactive with an initial question
    ```
     ai chat --interactive --question "What is the capital of France?"
    ```
   * Interactive with a system prompt
    ```
     ai chat --interactive --system "Always answer in French."
    ```

 * Answers and chat history
   * Output answer to a file
   ```
    ai chat --question "What is the capital of France?" --output-answer answer.txt
   ```
   * Output chat history to a file
   ```
    ai chat --interactive --output-chat-history history.jsonl
   ```
   * Input chat history from a file
   ```
    ai chat --interactive --input-chat-history history.jsonl
   ```
